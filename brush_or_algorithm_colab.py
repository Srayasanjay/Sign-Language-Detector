# -*- coding: utf-8 -*-
"""BRUSH_OR_ALGORITHM_COLAB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jn6SkeCBGpRbyOPp5gpnd6bK3zswyNSn
"""

from google.colab import drive
drive.mount('/content/drive')

#Dataset Loading and preprocessing
import os
import cv2
import numpy as np
from google.colab import drive
from sklearn.model_selection import train_test_split

drive.mount('/content/drive')

DATASET_PATH = "/content/drive/MyDrive/"
AI_DIR = os.path.join(DATASET_PATH, "AI_GENERATED")
HUMAN_DIR = os.path.join(DATASET_PATH, "NON_AI_GENERATED")

IMG_SIZE = 224  # Standard size for CNN input

# to load images
def load_images(folder, label):
    data = []
    for file in os.listdir(folder):
        img_path = os.path.join(folder, file)

        # Read image with OpenCV
        img = cv2.imread(img_path)

        # Handle potential issues with loading images
        if img is None:
            print(f"Skipping invalid image: {img_path}")
            continue

        # Resize image to match model input size
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))

        # Convert to RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Append image and corresponding label
        data.append((img, label))

    return data

# Load both AI-generated and human-created images
ai_images = load_images(AI_DIR, 1)
human_images = load_images(HUMAN_DIR, 0)

# Combine datasets and shuffle
dataset = ai_images + human_images
np.random.shuffle(dataset)

# Prepare input and labels
X, y = zip(*dataset)
X = np.array(X) / 255.0  # Normalize pixel values (0-1)
y = np.array(y)

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Save dataset in Drive for future use
np.save("/content/drive/MyDrive/X_train.npy", X_train)
np.save("/content/drive/MyDrive/X_test.npy", X_test)
np.save("/content/drive/MyDrive/y_train.npy", y_train)
np.save("/content/drive/MyDrive/y_test.npy", y_test)

print(f"Dataset saved! Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

#CNN MODEL DEFINITION AND TRAINING
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import numpy as np
import os
# Mount Google Drive
import numpy as np

# Load dataset correctly
X_train = np.load("/content/drive/MyDrive/X_train.npy", allow_pickle=True)
X_test = np.load("/content/drive/MyDrive/X_test.npy", allow_pickle=True)
y_train = np.load("/content/drive/MyDrive/y_train.npy", allow_pickle=True)
y_test = np.load("/content/drive/MyDrive/y_test.npy", allow_pickle=True)

# Print shape to confirm data is loaded correctly
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)


# Define CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification (AI vs Human)
])

# Compile model
model.compile(optimizer=Adam(learning_rate=0.0001), loss="binary_crossentropy", metrics=["accuracy"])

# Train model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Save trained model
model.save("/content/drive/MyDrive/ai_art_classifier.h5")

#GE-CNN MODEL DEFINITION AND TRAINING
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Multiply, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import numpy as np
from google.colab import drive

drive.mount('/content/drive')


# Load dataset
X_train = np.load("/content/drive/MyDrive/X_train.npy", allow_pickle=True)
X_test = np.load("/content/drive/MyDrive/X_test.npy", allow_pickle=True)
y_train = np.load("/content/drive/MyDrive/y_train.npy", allow_pickle=True)
y_test = np.load("/content/drive/MyDrive/y_test.npy", allow_pickle=True)

# Print shapes
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# Define gated convolution block
def gated_conv2d(x, filters, kernel_size, strides=(1,1), padding='same'):
    conv_feature = Conv2D(filters, kernel_size, strides=strides, padding=padding, activation='relu')(x)
    conv_gate = Conv2D(filters, kernel_size, strides=strides, padding=padding, activation='sigmoid')(x)
    return Multiply()([conv_feature, conv_gate])

# Build GCNN model
input_layer = Input(shape=(224, 224, 3))
x = gated_conv2d(input_layer, 32, (3, 3))
x = MaxPooling2D((2, 2))(x)
x = gated_conv2d(x, 64, (3, 3))
x = MaxPooling2D((2, 2))(x)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
output_layer = Dense(1, activation='sigmoid')(x)

model = Model(inputs=input_layer, outputs=output_layer)

# Compile model
model.compile(optimizer=Adam(learning_rate=0.0001), loss="binary_crossentropy", metrics=["accuracy"])

# Train model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Save model
model.save("/content/drive/MyDrive/ai_art_classifier_gcnn.h5")

model.save("/content/drive/MyDrive/ai_art_classifier.h5")

#ACCURACY MEASUREMENTS FOR CNN MODEL
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import drive

drive.mount('/content/drive')


# Load the trained model
model_path = "/content/drive/MyDrive/ai_art_classifier.h5"
model = load_model(model_path)

# Load test dataset
X_test = np.load("/content/drive/MyDrive/X_test.npy")
y_test = np.load("/content/drive/MyDrive/y_test.npy")

# Evaluate model performance
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")
print(f"Test Loss: {test_loss:.4f}")

# Make predictions
y_pred_prob = model.predict(X_test)  # Get probability scores
y_pred = (y_pred_prob >= 0.5).astype(int)  # Convert probabilities to binary labels

# Generate classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=["Human Art", "AI Art"]))

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Human Art", "AI Art"], yticklabels=["Human Art", "AI Art"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

#ACCURACY MEASUREMENTS FOR GE-CNN MODEL
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import load_model
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import drive

drive.mount('/content/drive')


# Load the trained model
model_path = "/content/drive/MyDrive/ai_art_classifier_gcnn.h5"
model = load_model(model_path)

# Load test dataset
X_test = np.load("/content/drive/MyDrive/X_test.npy")
y_test = np.load("/content/drive/MyDrive/y_test.npy")

# Evaluate model performance
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")
print(f"Test Loss: {test_loss:.4f}")

# Make predictions
y_pred_prob = model.predict(X_test)  # Get probability scores
y_pred = (y_pred_prob >= 0.5).astype(int)  # Convert probabilities to binary labels

# Generate classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=["Human Art", "AI Art"]))

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Human Art", "AI Art"], yticklabels=["Human Art", "AI Art"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

#TESTING MODEL WITH AN IMAGE
import numpy as np
import cv2
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from google.colab import files
from PIL import Image
from google.colab import drive

drive.mount('/content/drive')

print("CNN MODEL PREDICTION")
# Load the trained model
model_path = "/content/drive/MyDrive/ai_art_classifier.h5"
model = load_model(model_path)

# Upload an image
uploaded = files.upload()

# Get the uploaded image filename
image_filename = list(uploaded.keys())[0]

# Load and preprocess the image
IMG_SIZE = 224  # Ensure it matches the model input size

def preprocess_image(image_path):
    """Load an image, resize, normalize, and prepare for model prediction."""
    img = Image.open(image_path).convert("RGB")  # Ensure 3 channels
    img = img.resize((IMG_SIZE, IMG_SIZE))  # Resize to match model input
    img_array = np.array(img) / 255.0  # Normalize pixel values (0-1)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array, img  # Return both array and original image for display

# Preprocess the uploaded image
image_array, original_image = preprocess_image(image_filename)

# Make prediction
y_pred_prob = model.predict(image_array)[0][0]  # Get probability score

# Convert probability to label
predicted_label = "AI Art" if y_pred_prob >= 0.5 else "Human Art"
confidence = (y_pred_prob if y_pred_prob >= 0.5 else 1 - y_pred_prob) * 100  # Convert to percentage

# Display the image with prediction
plt.imshow(original_image)
plt.axis("off")
plt.title(f"Prediction: {predicted_label}\nConfidence: {confidence:.2f}%")  # Add percentage symbol
plt.show()


print("\nGE-CNN MODEL PREDICTION")

model_path = "/content/drive/MyDrive/ai_art_classifier_gcnn.h5"
model = load_model(model_path)


# Make prediction
y_pred_prob = model.predict(image_array)[0][0]  # Get probability score

# Convert probability to label
predicted_label = "AI Art" if y_pred_prob >= 0.5 else "Human Art"
confidence = (y_pred_prob if y_pred_prob >= 0.5 else 1 - y_pred_prob) * 100  # Convert to percentage

# Display the image with prediction
plt.imshow(original_image)
plt.axis("off")
plt.title(f"Prediction: {predicted_label}\nConfidence: {confidence:.2f}%")  # Add percentage symbol
plt.show()

#CONVERT THE MODEL TO TFLITE FOR FLUTTER

import tensorflow as tf
from google.colab import drive
from tensorflow.keras.models import load_model

drive.mount('/content/drive')

model_path = "/content/drive/MyDrive/ai_art_classifier.h5"
model = load_model(model_path)

# Convert to .tflite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the .tflite model
with open("/content/drive/MyDrive/ai_art_classifier.tflite", "wb") as f:
    f.write(tflite_model)

print("Model converted to ai_art_classifier.tflite and saved successfully!")

# Save the TFLite model to Google Drive
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Define the save path
save_path = "/content/drive/MyDrive/gradcam_model.tflite"

# Save the model to Google Drive
with open(save_path, "wb") as f:
    f.write(tflite_model)

print(f"TFLite model saved successfully at {save_path}")

# Install TensorFlow and other required libraries
!pip install tensorflow
!pip install opencv-python
!pip install matplotlib
!pip install Pillow

'/content/drive/MyDrive/sample_image.jpg'